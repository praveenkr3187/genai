<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Prediction Architecture</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            min-height: 100vh;
            color: #333;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            color: white;
        }

        .header h1 {
            font-size: 3rem;
            margin-bottom: 15px;
            font-weight: 300;
            letter-spacing: -1px;
        }

        .header .subtitle {
            font-size: 1.3rem;
            opacity: 0.9;
            font-weight: 300;
        }

        .main-panel {
            background: white;
            border-radius: 8px;
            padding: 40px;
            margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.15);
        }

        .section {
            margin-bottom: 40px;
        }

        .section-title {
            font-size: 1.8rem;
            color: #2c3e50;
            margin-bottom: 25px;
            font-weight: 600;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }

        .input-area {
            margin-bottom: 30px;
        }

        .input-label {
            display: block;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 1.1rem;
        }

        .text-input {
            width: 100%;
            padding: 18px;
            font-size: 1.1rem;
            border: 2px solid #e0e6ed;
            border-radius: 6px;
            resize: vertical;
            min-height: 100px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            background: #f8f9fa;
            transition: all 0.3s ease;
        }

        .text-input:focus {
            outline: none;
            border-color: #3498db;
            background: white;
            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.1);
        }

        .primary-button {
            background: linear-gradient(135deg, #3498db, #2980b9);
            color: white;
            border: none;
            padding: 16px 32px;
            font-size: 1.1rem;
            border-radius: 6px;
            cursor: pointer;
            margin-top: 15px;
            font-weight: 600;
            transition: all 0.3s ease;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .primary-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(52, 152, 219, 0.3);
        }

        .primary-button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .process-pipeline {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .pipeline-stage {
            background: #f8f9fa;
            border-radius: 6px;
            padding: 25px;
            text-align: center;
            transition: all 0.4s ease;
            border: 2px solid transparent;
            position: relative;
        }

        .pipeline-stage.active {
            background: linear-gradient(135deg, #3498db, #2980b9);
            color: white;
            transform: translateY(-5px);
            border-color: #2980b9;
            box-shadow: 0 10px 25px rgba(52, 152, 219, 0.3);
        }

        .stage-number {
            display: inline-block;
            width: 40px;
            height: 40px;
            background: #34495e;
            color: white;
            border-radius: 50%;
            line-height: 40px;
            font-weight: bold;
            margin-bottom: 15px;
        }

        .pipeline-stage.active .stage-number {
            background: white;
            color: #3498db;
        }

        .stage-title {
            font-weight: 600;
            margin-bottom: 10px;
            font-size: 1.1rem;
        }

        .stage-description {
            font-size: 0.95rem;
            opacity: 0.8;
            line-height: 1.4;
        }

        .token-analysis {
            background: #f8f9fa;
            border-radius: 6px;
            padding: 25px;
            margin: 25px 0;
            min-height: 120px;
        }

        .token-row {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            align-items: center;
            margin-bottom: 20px;
        }

        .row-label {
            font-weight: 600;
            color: #2c3e50;
            min-width: 120px;
            margin-right: 15px;
        }

        .token {
            background: #3498db;
            color: white;
            padding: 10px 18px;
            border-radius: 4px;
            font-size: 1rem;
            font-weight: 500;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            transition: all 0.3s ease;
            position: relative;
        }

        .token.predicted {
            background: #e74c3c;
            animation: highlight 2s ease-in-out infinite;
            border: 2px solid #c0392b;
        }

        .token.processing {
            background: #f39c12;
            animation: processing 1s ease-in-out infinite;
        }

        .analysis-controls {
            background: #f8f9fa;
            border-radius: 6px;
            padding: 20px;
            margin: 30px 0;
        }

        .controls-title {
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 15px;
        }

        .control-buttons {
            display: flex;
            gap: 15px;
            flex-wrap: wrap;
        }

        .control-button {
            background: white;
            border: 2px solid #e0e6ed;
            padding: 12px 24px;
            border-radius: 4px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.95rem;
            font-weight: 500;
        }

        .control-button:hover {
            background: #3498db;
            color: white;
            border-color: #3498db;
        }

        .control-button.active {
            background: #3498db;
            color: white;
            border-color: #3498db;
        }

        .analysis-display {
            background: #f8f9fa;
            border-radius: 6px;
            padding: 25px;
            margin: 25px 0;
            max-height: 500px;
            overflow-y: auto;
        }

        .layer-item {
            background: white;
            border-radius: 4px;
            padding: 18px;
            margin-bottom: 12px;
            border-left: 4px solid #e0e6ed;
            transition: all 0.4s ease;
        }

        .layer-item.processing {
            border-left-color: #3498db;
            background: linear-gradient(135deg, #3498db, #2980b9);
            color: white;
            transform: translateX(10px);
            box-shadow: 0 5px 15px rgba(52, 152, 219, 0.3);
        }

        .layer-name {
            font-weight: 600;
            margin-bottom: 8px;
            font-size: 1.05rem;
        }

        .layer-description {
            font-size: 0.9rem;
            opacity: 0.8;
        }

        .computation-details {
            font-size: 0.85rem;
            margin-top: 8px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            opacity: 0.9;
        }

        .layer-progress {
            height: 6px;
            background: #e0e6ed;
            border-radius: 3px;
            overflow: hidden;
            margin-top: 12px;
        }

        .layer-progress-fill {
            height: 100%;
            background: #3498db;
            border-radius: 3px;
            transition: width 0.8s ease;
        }

        .probability-analysis {
            background: white;
            border-radius: 6px;
            padding: 25px;
            margin: 25px 0;
        }

        .probability-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 18px;
            padding: 12px 0;
            border-bottom: 1px solid #ecf0f1;
        }

        .probability-item:last-child {
            border-bottom: none;
        }

        .probability-word {
            font-weight: 600;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            color: #2c3e50;
        }

        .probability-bar {
            flex: 1;
            height: 24px;
            background: #ecf0f1;
            border-radius: 12px;
            margin: 0 20px;
            overflow: hidden;
        }

        .probability-fill {
            height: 100%;
            background: linear-gradient(90deg, #3498db, #2980b9);
            border-radius: 12px;
            transition: width 1.2s ease;
        }

        .probability-value {
            font-weight: 600;
            color: #3498db;
            min-width: 60px;
            text-align: right;
        }

        .attention-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }

        .attention-cell {
            background: white;
            border-radius: 4px;
            padding: 20px;
            text-align: center;
            font-weight: 600;
            color: white;
            transition: all 0.3s ease;
        }

        .attention-cell:hover {
            transform: scale(1.05);
        }

        .attention-weight {
            font-size: 0.85rem;
            margin-top: 8px;
            opacity: 0.9;
        }

        .metrics-panel {
            background: white;
            border-radius: 8px;
            padding: 30px;
            margin-top: 20px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .metrics-title {
            font-size: 1.6rem;
            color: #2c3e50;
            margin-bottom: 25px;
            font-weight: 600;
            text-align: center;
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 25px;
        }

        .metric-card {
            background: #f8f9fa;
            border-radius: 6px;
            padding: 25px;
            text-align: center;
            border-left: 4px solid #3498db;
        }

        .metric-value {
            font-size: 2.2rem;
            font-weight: 300;
            color: #3498db;
            margin-bottom: 8px;
        }

        .metric-label {
            color: #7f8c8d;
            font-size: 0.95rem;
            font-weight: 500;
        }

        .hidden {
            display: none;
        }

        @keyframes highlight {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.05); opacity: 0.9; }
        }

        @keyframes processing {
            0%, 100% { transform: translateY(0); }
            50% { transform: translateY(-3px); }
        }

        .architecture-note {
            background: #ecf0f1;
            border-left: 4px solid #3498db;
            padding: 20px;
            margin: 30px 0;
            border-radius: 0 6px 6px 0;
        }

        .note-title {
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 10px;
        }

        .note-content {
            color: #7f8c8d;
            line-height: 1.6;
        }

        .computation-output {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 4px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 0.9rem;
            margin: 10px 0;
            white-space: pre-wrap;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Neural Network Prediction Architecture</h1>
            <p class="subtitle">Real-time Computational Analysis of Language Model Inference</p>
        </div>

        <div class="main-panel">
            <div class="section">
                <h2 class="section-title">Interactive Prediction Analysis</h2>
                
                <div class="input-area">
                    <label class="input-label" for="userInput">Input Sequence</label>
                    <textarea 
                        class="text-input" 
                        id="userInput" 
                        placeholder="Enter text to analyze the prediction mechanism..."
                    >The cat sat on the</textarea>
                    <button class="primary-button" id="analyzeBtn" onclick="startAnalysis()">
                        Execute Analysis
                    </button>
                </div>

                <div class="process-pipeline" id="processSteps">
                    <div class="pipeline-stage" data-step="tokenize">
                        <div class="stage-number">1</div>
                        <div class="stage-title">Tokenization</div>
                        <div class="stage-description">Text segmentation into discrete tokens</div>
                    </div>
                    <div class="pipeline-stage" data-step="embed">
                        <div class="stage-number">2</div>
                        <div class="stage-title">Embedding</div>
                        <div class="stage-description">Vector representation mapping</div>
                    </div>
                    <div class="pipeline-stage" data-step="attention">
                        <div class="stage-number">3</div>
                        <div class="stage-title">Attention</div>
                        <div class="stage-description">Contextual relationship modeling</div>
                    </div>
                    <div class="pipeline-stage" data-step="process">
                        <div class="stage-number">4</div>
                        <div class="stage-title">Processing</div>
                        <div class="stage-description">Multi-layer neural computation</div>
                    </div>
                    <div class="pipeline-stage" data-step="predict">
                        <div class="stage-number">5</div>
                        <div class="stage-title">Prediction</div>
                        <div class="stage-description">Probability distribution generation</div>
                    </div>
                </div>

                <div class="token-analysis" id="tokenDisplay">
                    <div class="token-row" id="inputTokens">
                        <span class="row-label">Input Tokens:</span>
                    </div>
                    <div class="token-row" id="outputTokens">
                        <span class="row-label">Predicted Token:</span>
                    </div>
                </div>
            </div>

            <div class="section" id="analysisSection" style="display: none;">
                <h2 class="section-title">Detailed Architecture Analysis</h2>

                <div class="analysis-controls">
                    <div class="controls-title">Analysis Options</div>
                    <div class="control-buttons">
                        <button class="control-button" onclick="showLayers()">Layer Processing</button>
                        <button class="control-button" onclick="showAttention()">Attention Mechanisms</button>
                        <button class="control-button" onclick="showProbabilities()">Output Probabilities</button>
                        <button class="control-button" onclick="resetDemo()">Reset Analysis</button>
                    </div>
                </div>

                <div class="analysis-display" id="analysisDisplay"></div>
            </div>

            <div class="architecture-note">
                <div class="note-title">Real Computation Notice</div>
                <div class="note-content">
                    This demonstration performs actual mathematical computations including tokenization, embedding vector operations, 
                    attention weight calculations, and probability distributions based on the input sequence. While simplified 
                    compared to production models, all calculations are computed in real-time.
                </div>
            </div>
        </div>

        <div class="metrics-panel">
            <h3 class="metrics-title">Computational Metrics</h3>
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-value" id="tokenCount">0</div>
                    <div class="metric-label">Tokens Processed</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value" id="embeddingDim">128</div>
                    <div class="metric-label">Embedding Dimension</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value" id="vocabSize">1000</div>
                    <div class="metric-label">Vocabulary Size</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value" id="attentionHeads">8</div>
                    <div class="metric-label">Attention Heads</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value" id="computeTime">0ms</div>
                    <div class="metric-label">Compute Time</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value" id="totalOps">0</div>
                    <div class="metric-label">Operations</div>
                </div>
            </div>
        </div>
    </div>

    <script>
        let isProcessing = false;
        let currentTokens = [];
        let tokenEmbeddings = [];
        let attentionWeights = [];
        let computationResults = {};

        // Simple vocabulary for demonstration
        const vocabulary = [
            'the', 'cat', 'sat', 'on', 'mat', 'dog', 'ran', 'jump', 'over', 'under',
            'big', 'small', 'red', 'blue', 'house', 'car', 'tree', 'book', 'table', 'chair',
            'and', 'but', 'or', 'if', 'then', 'when', 'where', 'how', 'why', 'what',
            'quickly', 'slowly', 'happy', 'sad', 'bright', 'dark', 'hot', 'cold', 'new', 'old',
            'walk', 'run', 'jump', 'sit', 'stand', 'look', 'see', 'hear', 'speak', 'think'
        ];

        const embeddingDim = 128;
        const attentionHeads = 8;

        // Initialize random embeddings for vocabulary
        let wordEmbeddings = {};
        vocabulary.forEach(word => {
            wordEmbeddings[word] = Array.from({length: embeddingDim}, () => (Math.random() - 0.5) * 2);
        });

        function tokenize(text) {
            // Real tokenization - split by whitespace and punctuation
            return text.toLowerCase()
                      .replace(/[.,!?;]/g, ' ')
                      .split(/\s+/)
                      .filter(t => t.length > 0);
        }

        function getEmbedding(token) {
            // Return embedding vector or random vector for unknown words
            if (wordEmbeddings[token]) {
                return [...wordEmbeddings[token]];
            }
            // Unknown word - create random embedding
            return Array.from({length: embeddingDim}, () => (Math.random() - 0.5) * 2);
        }

        function dotProduct(a, b) {
            return a.reduce((sum, val, i) => sum + val * b[i], 0);
        }

        function softmax(logits) {
            const maxLogit = Math.max(...logits);
            const expLogits = logits.map(x => Math.exp(x - maxLogit));
            const sumExp = expLogits.reduce((sum, x) => sum + x, 0);
            return expLogits.map(x => x / sumExp);
        }

        function computeAttention(queryEmbeddings, keyEmbeddings, valueEmbeddings) {
            const seqLen = queryEmbeddings.length;
            const attentionScores = [];
            
            // Compute attention scores for each position
            for (let i = 0; i < seqLen; i++) {
                const scores = [];
                for (let j = 0; j < seqLen; j++) {
                    // Simplified attention: dot product of query and key
                    const score = dotProduct(queryEmbeddings[i], keyEmbeddings[j]) / Math.sqrt(embeddingDim);
                    scores.push(score);
                }
                attentionScores.push(softmax(scores));
            }
            
            return attentionScores;
        }

        function computeLanguageModelLogits(contextEmbeddings) {
            // Simplified language model head - compute logits for each vocabulary word
            const logits = [];
            
            // Use the last token's embedding as context
            const contextVector = contextEmbeddings[contextEmbeddings.length - 1];
            
            vocabulary.forEach(word => {
                const wordEmb = wordEmbeddings[word];
                // Compute similarity score
                const logit = dotProduct(contextVector, wordEmb) / embeddingDim;
                logits.push(logit);
            });
            
            return logits;
        }

        async function startAnalysis() {
            if (isProcessing) return;

            const startTime = performance.now();
            const input = document.getElementById('userInput').value.trim();
            if (!input) {
                alert('Please enter text for analysis.');
                return;
            }

            isProcessing = true;
            document.getElementById('analyzeBtn').disabled = true;
            document.getElementById('analysisSection').style.display = 'block';

            // Step 1: Tokenization
            currentTokens = tokenize(input);
            document.getElementById('tokenCount').textContent = currentTokens.length;

            await executeTokenization();
            await executePipelineStages();
            
            // Step 2: Embeddings
            tokenEmbeddings = currentTokens.map(token => getEmbedding(token));
            
            // Step 3: Attention computation
            attentionWeights = computeAttention(tokenEmbeddings, tokenEmbeddings, tokenEmbeddings);
            
            // Step 4: Language model prediction
            const logits = computeLanguageModelLogits(tokenEmbeddings);
            const probabilities = softmax(logits);
            
            // Store results
            computationResults = {
                tokens: currentTokens,
                embeddings: tokenEmbeddings,
                attention: attentionWeights,
                logits: logits,
                probabilities: probabilities
            };
            
            await generatePredictionOutput();

            const endTime = performance.now();
            document.getElementById('computeTime').textContent = `${Math.round(endTime - startTime)}ms`;
            document.getElementById('totalOps').textContent = 
                (currentTokens.length * embeddingDim * attentionHeads + vocabulary.length).toLocaleString();

            document.getElementById('analyzeBtn').disabled = false;
            isProcessing = false;
        }

        async function executeTokenization() {
            const inputContainer = document.getElementById('inputTokens');
            const baseContent = inputContainer.innerHTML;
            
            for (let i = 0; i < currentTokens.length; i++) {
                await new Promise(resolve => setTimeout(resolve, 300));
                const tokenElement = document.createElement('span');
                tokenElement.className = 'token processing';
                tokenElement.textContent = currentTokens[i];
                tokenElement.title = `Token ${i + 1}: "${currentTokens[i]}"`;
                inputContainer.appendChild(tokenElement);
                
                setTimeout(() => {
                    tokenElement.classList.remove('processing');
                }, 600);
            }
        }

        async function executePipelineStages() {
            const stages = document.querySelectorAll('.pipeline-stage');
            
            for (let stage of stages) {
                stage.classList.add('active');
                await new Promise(resolve => setTimeout(resolve, 1000));
                stage.classList.remove('active');
            }
        }

        async function generatePredictionOutput() {
            const outputContainer = document.getElementById('outputTokens');
            
            await new Promise(resolve => setTimeout(resolve, 600));
            
            // Get the most likely next token
            const maxProbIndex = computationResults.probabilities.indexOf(
                Math.max(...computationResults.probabilities)
            );
            const predictedToken = vocabulary[maxProbIndex];
            const confidence = computationResults.probabilities[maxProbIndex];
            
            const predictionElement = document.createElement('span');
            predictionElement.className = 'token predicted';
            predictionElement.textContent = predictedToken;
            predictionElement.title = `Predicted: "${predictedToken}" (${(confidence * 100).toFixed(1)}% confidence)`;
            outputContainer.appendChild(predictionElement);
        }

        async function showLayers() {
            const display = document.getElementById('analysisDisplay');
            display.innerHTML = '<h4 style="margin-bottom: 20px; color: #2c3e50;">Layer-by-Layer Processing</h4>';

            const layers = [
                {
                    name: "Input Embeddings",
                    description: "Convert tokens to dense vector representations",
                    computation: () => {
                        const avgNorm = tokenEmbeddings.reduce((sum, emb) => 
                            sum + Math.sqrt(emb.reduce((s, x) => s + x*x, 0)), 0) / tokenEmbeddings.length;
                        return `Embedding vectors: ${currentTokens.length}x${embeddingDim}\nAverage L2 norm: ${avgNorm.toFixed(3)}`;
                    }
                },
                {
                    name: "Multi-Head Attention",
                    description: "Compute attention weights between all token pairs",
                    computation: () => {
                        const totalAttention = attentionWeights.flat().reduce((sum, w) => sum + w, 0);
                        const maxAttention = Math.max(...attentionWeights.flat());
                        return `Attention matrix: ${currentTokens.length}x${currentTokens.length}\nMax attention weight: ${maxAttention.toFixed(3)}\nTotal attention sum: ${totalAttention.toFixed(3)}`;
                    }
                },
                {
                    name: "Feed Forward Network",
                    description: "Apply position-wise neural network transformations",
                    computation: () => {
                        const operations = currentTokens.length * embeddingDim * 4; // 4x expansion typical
                        return `FFN operations: ${operations.toLocaleString()}\nIntermediate dim: ${embeddingDim * 4}`;
                    }
                },
                {
                    name: "Output Projection",
                    description: "Project hidden states to vocabulary logits",
                    computation: () => {
                        const maxLogit = Math.max(...computationResults.logits);
                        const minLogit = Math.min(...computationResults.logits);
                        return `Vocabulary projection: ${embeddingDim}x${vocabulary.length}\nLogit range: [${minLogit.toFixed(2)}, ${maxLogit.toFixed(2)}]`;
                    }
                },
                {
                    name: "Softmax Normalization",
                    description: "Convert logits to probability distribution",
                    computation: () => {
                        const entropy = -computationResults.probabilities.reduce((sum, p) => 
                            sum + (p > 0 ? p * Math.log2(p) : 0), 0);
                        const maxProb = Math.max(...computationResults.probabilities);
                        return `Probability distribution over ${vocabulary.length} tokens\nEntropy: ${entropy.toFixed(3)} bits\nMax probability: ${(maxProb * 100).toFixed(1)}%`;
                    }
                }
            ];

            for (let i = 0; i < layers.length; i++) {
                const layer = layers[i];
                const layerElement = document.createElement('div');
                layerElement.className = 'layer-item';
                layerElement.innerHTML = `
                    <div class="layer-name">Layer ${i + 1}: ${layer.name}</div>
                    <div class="layer-description">${layer.description}</div>
                    <div class="computation-output">${layer.computation()}</div>
                    <div class="layer-progress">
                        <div class="layer-progress-fill" style="width: 0%"></div>
                    </div>
                `;
                display.appendChild(layerElement);

                setTimeout(() => {
                    layerElement.classList.add('processing');
                    const progressBar = layerElement.querySelector('.layer-progress-fill');
                    progressBar.style.width = '100%';
                    
                    setTimeout(() => {
                        layerElement.classList.remove('processing');
                    }, 1500);
                }, i * 600);
            }
        }

        function showAttention() {
            const display = document.getElementById('analysisDisplay');
            
            if (!attentionWeights.length) {
                display.innerHTML = '<p>Please run analysis first to compute attention weights.</p>';
                return;
            }
            
            display.innerHTML = `
                <h4 style="margin-bottom: 20px; color: #2c3e50;">Attention Weight Matrix</h4>
                <p style="margin-bottom: 25px; color: #7f8c8d;">Real computed attention weights between tokens</p>
                <div style="overflow-x: auto;">
                    <table style="width: 100%; border-collapse: collapse; font-family: monospace;">
                        <thead>
                            <tr>
                                <th style="padding: 10px; border: 1px solid #ddd; background: #f8f9fa;">From \\ To</th>
                                ${currentTokens.map(token => 
                                    `<th style="padding: 10px; border: 1px solid #ddd; background: #f8f9fa;">${token}</th>`
                                ).join('')}
                            </tr>
                        </thead>
                        <tbody>
                            ${attentionWeights.map((weights, i) => `
                                <tr>
                                    <td style="padding: 10px; border: 1px solid #ddd; background: #f8f9fa; font-weight: bold;">
                                        ${currentTokens[i]}
                                    </td>
                                    ${weights.map(weight => {
                                        const intensity = weight;
                                        const bgColor = `rgba(52, 152, 219, ${intensity})`;
                                        const textColor = intensity > 0.5 ? 'white' : 'black';
                                        return `<td style="padding: 10px; border: 1px solid #ddd; background: ${bgColor}; color: ${textColor}; text-align: center;">
                                            ${weight.toFixed(3)}
                                        </td>`;
                                    }).join('')}
                                </tr>
                            `).join('')}
                        </tbody>
                    </table>
                </div>
                <div style="margin-top: 20px; padding: 15px; background: #f8f9fa; border-radius: 6px;">
                    <h5>Attention Analysis:</h5>
                    <div class="computation-output">
${attentionWeights.map((weights, i) => {
    const maxIdx = weights.indexOf(Math.max(...weights));
    const maxWeight = weights[maxIdx];
    return `Token "${currentTokens[i]}" attends most to "${currentTokens[maxIdx]}" (${maxWeight.toFixed(3)})`;
}).join('\n')}
                    </div>
                </div>
            `;
        }

        function showProbabilities() {
            const display = document.getElementById('analysisDisplay');
            
            if (!computationResults.probabilities) {
                display.innerHTML = '<p>Please run analysis first to compute probabilities.</p>';
                return;
            }
            
            // Get top 10 predictions
            const probWithIndex = computationResults.probabilities.map((prob, idx) => ({prob, idx, word: vocabulary[idx]}));
            probWithIndex.sort((a, b) => b.prob - a.prob);
            const topPredictions = probWithIndex.slice(0, 10);
            
            display.innerHTML = `
                <div class="probability-analysis">
                    <h4 style="margin-bottom: 20px; color: #2c3e50;">Computed Probability Distribution</h4>
                    <p style="margin-bottom: 25px; color: #7f8c8d;">Top 10 predictions with actual computed probabilities</p>
                    ${topPredictions.map((item, index) => `
                        <div class="probability-item">
                            <span class="probability-word">${item.word}</span>
                            <div class="probability-bar">
                                <div class="probability-fill" style="width: ${(item.prob * 100)}%"></div>
                            </div>
                            <span class="probability-value">${(item.prob * 100).toFixed(2)}%</span>
                        </div>
                    `).join('')}
                    <div style="margin-top: 25px; padding: 15px; background: #f8f9fa; border-radius: 6px;">
                        <h5>Statistical Properties:</h5>
                        <div class="computation-output">
Entropy: ${(-computationResults.probabilities.reduce((sum, p) => sum + (p > 0 ? p * Math.log2(p) : 0), 0)).toFixed(3)} bits
Perplexity: ${Math.pow(2, -computationResults.probabilities.reduce((sum, p) => sum + (p > 0 ? p * Math.log2(p) : 0), 0)).toFixed(2)}
Top-1 Probability: ${(Math.max(...computationResults.probabilities) * 100).toFixed(2)}%
Top-5 Probability: ${(topPredictions.slice(0, 5).reduce((sum, item) => sum + item.prob, 0) * 100).toFixed(2)}%
                        </div>
                    </div>
                </div>
            `;
        }

        function resetDemo() {
            document.getElementById('userInput').value = 'The cat sat on the';
            document.getElementById('inputTokens').innerHTML = '<span class="row-label">Input Tokens:</span>';
            document.getElementById('outputTokens').innerHTML = '<span class="row-label">Predicted Token:</span>';
            document.getElementById('analysisDisplay').innerHTML = '';
            document.getElementById('analysisSection').style.display = 'none';
            document.getElementById('tokenCount').textContent = '0';
            document.getElementById('computeTime').textContent = '0ms';
            document.getElementById('totalOps').textContent = '0';
            
            document.querySelectorAll('.pipeline-stage').forEach(stage => {
                stage.classList.remove('active');
            });
            
            document.querySelectorAll('.control-button').forEach(button => {
                button.classList.remove('active');
            });
            
            // Reset computation state
            currentTokens = [];
            tokenEmbeddings = [];
            attentionWeights = [];
            computationResults = {};
            
            isProcessing = false;
        }

        // Initialize random word embeddings for better predictions
        function initializeWordEmbeddings() {
            // Create more meaningful embeddings based on word similarity
            const semanticGroups = {
                animals: ['cat', 'dog'],
                actions: ['sat', 'ran', 'jump', 'walk', 'run', 'sit', 'stand'],
                objects: ['mat', 'chair', 'table', 'book', 'house', 'car', 'tree'],
                descriptors: ['big', 'small', 'red', 'blue', 'hot', 'cold', 'new', 'old'],
                connectors: ['and', 'but', 'or', 'if', 'then'],
                determiners: ['the', 'a'],
                prepositions: ['on', 'under', 'over', 'near']
            };

            // Initialize embeddings with some semantic structure
            Object.entries(semanticGroups).forEach((group, groupIdx) => {
                const [category, words] = group;
                const baseVector = Array.from({length: embeddingDim}, () => (Math.random() - 0.5) * 0.5);
                
                words.forEach(word => {
                    if (vocabulary.includes(word)) {
                        // Add group-specific pattern + individual variation
                        wordEmbeddings[word] = baseVector.map((val, i) => 
                            val + Math.sin(groupIdx * 2 + i * 0.1) * 0.3 + (Math.random() - 0.5) * 0.2
                        );
                    }
                });
            });

            // Fill remaining words with random embeddings
            vocabulary.forEach(word => {
                if (!wordEmbeddings[word]) {
                    wordEmbeddings[word] = Array.from({length: embeddingDim}, () => (Math.random() - 0.5) * 2);
                }
            });
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            initializeWordEmbeddings();
            resetDemo();
        });
    </script>
</body>
</html>